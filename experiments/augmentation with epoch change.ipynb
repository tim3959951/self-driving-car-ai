{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8bd3bc-94fc-4dd9-b018-7cb4e043cc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from opencv-python-headless) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2009c3de-04c3-4a48-a0a1-31a30a891c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class AugmentedDataGenerator(ImageDataGenerator):\n",
    "    def __init__(self, contrast_range=None, color_jitter_range=None, noise_range=None, *args, **kwargs):\n",
    "        self.contrast_range = contrast_range\n",
    "        self.color_jitter_range = color_jitter_range\n",
    "        self.noise_range = noise_range\n",
    "        super(AugmentedDataGenerator, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def __next__(self):\n",
    "        batch = super(AugmentedDataGenerator, self).__next__()\n",
    "        for i, image in enumerate(batch[0]):\n",
    "            # random brightness\n",
    "            if self.brightness_range:\n",
    "                if np.random.random() < 0.5:\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "                    brightness_factor = np.random.uniform(*self.brightness_range)\n",
    "                    image[:, :, 2] = image[:, :, 2] * brightness_factor\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "            # random contrast\n",
    "            if self.contrast_range:\n",
    "                if np.random.random() < 0.5:\n",
    "                    alpha = np.random.uniform(*self.contrast_range)\n",
    "                    image = cv2.convertScaleAbs(image, alpha=alpha)\n",
    "\n",
    "            # random color jitter\n",
    "            if self.color_jitter_range:\n",
    "                if np.random.random() < 0.5:\n",
    "                    noise = np.random.randint(-self.color_jitter_range, self.color_jitter_range, image.shape)\n",
    "                    image = cv2.add(image, noise)\n",
    "\n",
    "            # random noise\n",
    "            if self.noise_range:\n",
    "                if np.random.random() < 0.5:\n",
    "                    noise = np.random.normal(0, self.noise_range, image.shape)\n",
    "                    image = cv2.add(image, noise)\n",
    "\n",
    "            batch[0][i] = image\n",
    "\n",
    "        return batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5606aa-ccc9-49c2-a178-c0efd6bc2ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (1.3.5)\n",
      "Requirement already satisfied: packaging in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from keras-tuner) (2.29.0)\n",
      "Requirement already satisfied: kt-legacy in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->keras-tuner) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->keras-tuner) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->keras-tuner) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8343ad-9e47-42b3-8808-0b5d171f1b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7e9f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tim/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f71ccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('GPU is not available')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d33d3fb-8cfb-469b-8d20-7cf1bdcc2aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "# load train dataset\n",
    "train_df = pd.read_csv('/Users/tim/Desktop/postgraduate/semester 2/machine learning 2/assessment_project/machine-learning-in-science-ii-2023/training_norm.csv')\n",
    "train_images = []\n",
    "for image_id in train_df['image_id']:\n",
    "    image = cv2.imread(f'/Users/tim/Desktop/postgraduate/semester 2/machine learning 2/assessment_project/machine-learning-in-science-ii-2023/training_data/training_data/{image_id}.png')\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    train_images.append(image)\n",
    "train_images = np.array(train_images)\n",
    "train_angles = np.array(train_df['angle'])\n",
    "train_speeds = np.array(train_df['speed'])\n",
    "\n",
    "# load test dataset\n",
    "test_images = []\n",
    "for i in range(1, 1021):\n",
    "    image = cv2.imread(f'/Users/tim/Desktop/postgraduate/semester 2/machine learning 2/assessment_project/machine-learning-in-science-ii-2023/test_data/test_data/{i}.png')\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    test_images.append(image)\n",
    "test_images = np.array(test_images)\n",
    "test_ids = np.arange(1, 1021)\n",
    "\n",
    "# split the data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_df[['angle', 'speed']].values, test_size=0.2, random_state=42)\n",
    "\n",
    "# define the early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# image augmentation\n",
    "train_datagen = AugmentedDataGenerator(\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    contrast_range=[0.8, 1.2],\n",
    "    color_jitter_range=20,\n",
    "    noise_range=10\n",
    ")\n",
    "train_datagen.fit(X_train)\n",
    "val_datagen = AugmentedDataGenerator()\n",
    "val_datagen.fit(X_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc5aced-04ac-428e-959a-85d5dc52b052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from output/steering_angle_regression/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "def build_model(hp):\n",
    "    # input layer\n",
    "    input_layer = Input(shape=(240, 320, 3))\n",
    "\n",
    "    # convolutional layers\n",
    "    num_conv_layers = hp.Int('num_conv_layers', min_value=2, max_value=5, step=1)\n",
    "    conv_layer_filters = [hp.Choice(f'conv_layer_{i}_filters', values=[32, 64, 128, 256], ordered=False, default=64) for i in range(num_conv_layers)]\n",
    "    conv_layer_kernel_sizes = [hp.Choice(f'conv_layer_{i}_kernel_sizes', values=[3, 5, 7], ordered=False, default=3) for i in range(num_conv_layers)]\n",
    "    conv_layer_activations = [hp.Choice(f'conv_layer_{i}_activations', values=['relu', 'elu'], default='relu') for i in range(num_conv_layers)]\n",
    "    x = input_layer\n",
    "    for i in range(num_conv_layers):\n",
    "        x = Conv2D(filters=conv_layer_filters[i], kernel_size=conv_layer_kernel_sizes[i], activation=conv_layer_activations[i], padding='same')(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    num_dense_layers = hp.Int('num_dense_layers', min_value=1, max_value=3, step=1)\n",
    "    for i in range(num_dense_layers):\n",
    "        dense_layer_units = hp.Int(f'dense_layer_{i}_units', min_value=32, max_value=512, step=32)\n",
    "        dense_layer_activation = hp.Choice(f'dense_layer_{i}_activation', values=['relu', 'elu'], default='relu')\n",
    "        x = Dense(units=dense_layer_units, activation=dense_layer_activation)(x)\n",
    "        dropout_rate = hp.Float(f'dropout_{i}', min_value=0.0, max_value=0.5, step=0.1, default=0.25)\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "    # output layer\n",
    "    angle_output = Dense(units=1, name='angle_output')(x)\n",
    "    speed_output = Dense(units=1, name='speed_output')(x)\n",
    "    model = Model(inputs=input_layer, outputs=[angle_output, speed_output])\n",
    "\n",
    "    # compile the model(with Mac chip)\n",
    "    optimizer = Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log'))\n",
    "    loss = {'angle_output': 'mean_squared_error', 'speed_output': 'mean_squared_error'}\n",
    "    metrics = {'angle_output': 'mae', 'speed_output': 'mae'}\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "# define the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=20,\n",
    "    directory='output',\n",
    "    project_name='steering_angle_regression'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975c4a6-59c7-4319-af09-924963a8ebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "5                 |4                 |num_conv_layers\n",
      "256               |128               |conv_layer_0_filters\n",
      "128               |128               |conv_layer_1_filters\n",
      "7                 |5                 |conv_layer_0_kernel_sizes\n",
      "7                 |5                 |conv_layer_1_kernel_sizes\n",
      "relu              |elu               |conv_layer_0_activations\n",
      "relu              |elu               |conv_layer_1_activations\n",
      "1                 |1                 |num_dense_layers\n",
      "96                |160               |dense_layer_0_units\n",
      "relu              |elu               |dense_layer_0_activation\n",
      "0.1               |0.2               |dropout_0\n",
      "0.0090213         |0.0022124         |learning_rate\n",
      "32                |64                |conv_layer_2_filters\n",
      "128               |64                |conv_layer_3_filters\n",
      "3                 |3                 |conv_layer_2_kernel_sizes\n",
      "5                 |3                 |conv_layer_3_kernel_sizes\n",
      "elu               |relu              |conv_layer_2_activations\n",
      "relu              |relu              |conv_layer_3_activations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  6/345 [..............................] - ETA: 11:55 - loss: 824073519104.0000 - angle_output_loss: 719611559936.0000 - speed_output_loss: 104461950976.0000 - angle_output_mae: 376170.0000 - speed_output_mae: 141014.8906 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.6294s vs `on_train_batch_end` time: 1.4875s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.6294s vs `on_train_batch_end` time: 1.4875s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/345 [=========>....................] - ETA: 7:37 - loss: 40200372224.0000 - angle_output_loss: 35104591872.0000 - speed_output_loss: 5095779328.0000 - angle_output_mae: 18525.4160 - speed_output_mae: 6946.9092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG14XFamilyCommandBuffer: 0x322151e60>\n",
      "    label = <none> \n",
      "    device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "        name = Apple M2 Pro \n",
      "    commandQueue = <AGXG14XFamilyCommandQueue: 0x13a884400>\n",
      "        label = <none> \n",
      "        device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "            name = Apple M2 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/345 [===========>..................] - ETA: 6:50 - loss: 34101004288.0000 - angle_output_loss: 29778378752.0000 - speed_output_loss: 4322626560.0000 - angle_output_mae: 15714.8496 - speed_output_mae: 5893.0532"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG14XFamilyCommandBuffer: 0x3200efcc0>\n",
      "    label = <none> \n",
      "    device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "        name = Apple M2 Pro \n",
      "    commandQueue = <AGXG14XFamilyCommandQueue: 0x13a884400>\n",
      "        label = <none> \n",
      "        device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "            name = Apple M2 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258/345 [=====================>........] - ETA: 2:58 - loss: 19165292544.0000 - angle_output_loss: 16735910912.0000 - speed_output_loss: 2429383168.0000 - angle_output_mae: 8832.2080 - speed_output_mae: 3312.3330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG14XFamilyCommandBuffer: 0x31611ac50>\n",
      "    label = <none> \n",
      "    device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "        name = Apple M2 Pro \n",
      "    commandQueue = <AGXG14XFamilyCommandQueue: 0x13a884400>\n",
      "        label = <none> \n",
      "        device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "            name = Apple M2 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 761s 2s/step - loss: 14340099072.0000 - angle_output_loss: 12522356736.0000 - speed_output_loss: 1817744000.0000 - angle_output_mae: 6608.6733 - speed_output_mae: 2478.5925 - val_loss: 1.0804 - val_angle_output_loss: 0.3676 - val_speed_output_loss: 0.7128 - val_angle_output_mae: 0.5503 - val_speed_output_mae: 0.7753\n",
      "Epoch 2/50\n",
      "139/345 [===========>..................] - ETA: 6:58 - loss: 1.0714 - angle_output_loss: 0.3608 - speed_output_loss: 0.7106 - angle_output_mae: 0.5462 - speed_output_mae: 0.7752"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG14XFamilyCommandBuffer: 0x31c289ec0>\n",
      "    label = <none> \n",
      "    device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "        name = Apple M2 Pro \n",
      "    commandQueue = <AGXG14XFamilyCommandQueue: 0x13a884400>\n",
      "        label = <none> \n",
      "        device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "            name = Apple M2 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 752s 2s/step - loss: 1.0500 - angle_output_loss: 0.3519 - speed_output_loss: 0.6980 - angle_output_mae: 0.5393 - speed_output_mae: 0.7667 - val_loss: 1.0170 - val_angle_output_loss: 0.3418 - val_speed_output_loss: 0.6752 - val_angle_output_mae: 0.5311 - val_speed_output_mae: 0.7507\n",
      "Epoch 3/50\n",
      "126/345 [=========>....................] - ETA: 7:24 - loss: 0.9959 - angle_output_loss: 0.3299 - speed_output_loss: 0.6659 - angle_output_mae: 0.5218 - speed_output_mae: 0.7451"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG14XFamilyCommandBuffer: 0x34fedc910>\n",
      "    label = <none> \n",
      "    device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "        name = Apple M2 Pro \n",
      "    commandQueue = <AGXG14XFamilyCommandQueue: 0x13a884400>\n",
      "        label = <none> \n",
      "        device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "            name = Apple M2 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/345 [===========>..................] - ETA: 6:46 - loss: 0.9976 - angle_output_loss: 0.3304 - speed_output_loss: 0.6672 - angle_output_mae: 0.5225 - speed_output_mae: 0.7464"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG14XFamilyCommandBuffer: 0x32a66ec70>\n",
      "    label = <none> \n",
      "    device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "        name = Apple M2 Pro \n",
      "    commandQueue = <AGXG14XFamilyCommandQueue: 0x13a884400>\n",
      "        label = <none> \n",
      "        device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "            name = Apple M2 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/345 [============>.................] - ETA: 6:33 - loss: 0.9957 - angle_output_loss: 0.3297 - speed_output_loss: 0.6660 - angle_output_mae: 0.5219 - speed_output_mae: 0.7455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG14XFamilyCommandBuffer: 0x320438620>\n",
      "    label = <none> \n",
      "    device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "        name = Apple M2 Pro \n",
      "    commandQueue = <AGXG14XFamilyCommandQueue: 0x13a884400>\n",
      "        label = <none> \n",
      "        device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "            name = Apple M2 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/345 [===================>..........] - ETA: 3:45 - loss: 0.9870 - angle_output_loss: 0.3262 - speed_output_loss: 0.6608 - angle_output_mae: 0.5193 - speed_output_mae: 0.7421"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInternal Error (0000000e:Internal Error)\n",
      "\t<AGXG14XFamilyCommandBuffer: 0x327575ce0>\n",
      "    label = <none> \n",
      "    device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "        name = Apple M2 Pro \n",
      "    commandQueue = <AGXG14XFamilyCommandQueue: 0x13a884400>\n",
      "        label = <none> \n",
      "        device = <AGXG14SDevice: 0x2ca1fa400>\n",
      "            name = Apple M2 Pro \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/345 [====================>.........] - ETA: 3:21 - loss: 0.9929 - angle_output_loss: 0.3260 - speed_output_loss: 0.6669 - angle_output_mae: 0.5189 - speed_output_mae: 0.7443"
     ]
    }
   ],
   "source": [
    "# search for the best hyperparameters\n",
    "tuner.search(train_datagen.flow(X_train, y_train, batch_size=32), epochs=50, validation_data=val_datagen.flow(X_val, y_val, batch_size=32), callbacks=[early_stop])\n",
    "\n",
    "# get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "# save the best model as an .h5 file\n",
    "best_model.save('aug_with_epoch_change_model.h5')\n",
    "\n",
    "# train the model on the entire training dataset\n",
    "history = best_model.fit(train_datagen.flow(train_images, (train_angles, train_speeds), batch_size=32), epochs=100, validation_data=val_datagen.flow(X_val, y_val, batch_size=32), callbacks=[early_stop])\n",
    "\n",
    "# make predictions on the test set\n",
    "test_predictions = best_model.predict(test_images)\n",
    "\n",
    "# get the steering angle and speed predictions separately\n",
    "test_steering_predictions = test_predictions[0]\n",
    "test_speed_predictions = test_predictions[1]\n",
    "# speed adjustment\n",
    "if np.min(test_speed_predictions) < 0:\n",
    "    test_speed_predictions = test_speed_predictions - np.min(test_speed_predictions) #if there is negative num in spd column\n",
    "    max_val = np.max(test_speed_predictions)      \n",
    "    normalized_arr_spd = test_speed_predictions / max_val\n",
    "    test_speed_predictions = np.where(normalized_arr_spd >= 0.5, 1, 0)\n",
    "else:\n",
    "    max_val = np.max(test_speed_predictions)      \n",
    "    normalized_arr_spd = test_speed_predictions / max_val\n",
    "    test_speed_predictions = np.where(normalized_arr_spd >= 0.5, 1, 0)\n",
    "submission_df = pd.DataFrame({\n",
    "    'image_id': test_ids.flatten(),\n",
    "    'angle': test_steering_predictions.flatten(),\n",
    "    'speed': test_speed_predictions.flatten()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcfd04b-6e94-449b-8ad8-fecf7aaf28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_generator(images, angles, speeds, batch_size, datagen):\n",
    "    num_samples = len(images)\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_images = images[offset:offset+batch_size]\n",
    "            batch_angles = angles[offset:offset+batch_size]\n",
    "            batch_speeds = speeds[offset:offset+batch_size]\n",
    "\n",
    "            augmented_images = []\n",
    "            for img in batch_images:\n",
    "                augmented_img = datagen.random_transform(img)\n",
    "                augmented_images.append(augmented_img)\n",
    "\n",
    "            yield np.array(augmented_images), [np.array(batch_angles), np.array(batch_speeds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065b58bd-edef-4a3e-a5e0-ce8bef2ba93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = custom_generator(train_images, train_angles, train_speeds, 32, train_datagen)\n",
    "val_generator = custom_generator(X_val, y_val[:, 0], y_val[:, 1], 32, val_datagen)\n",
    "history = best_model.fit(train_generator, steps_per_epoch=len(train_images) // 32, epochs=100, validation_data=val_generator, validation_steps=len(X_val) // 32, callbacks=[early_stop])\n",
    "\n",
    "# make predictions on the test set\n",
    "test_predictions = best_model.predict(test_images)\n",
    "\n",
    "# get the steering angle and speed predictions separately\n",
    "test_steering_predictions = test_predictions[0]\n",
    "test_speed_predictions = test_predictions[1]\n",
    "\n",
    "# speed adjustment\n",
    "if np.min(test_speed_predictions) < 0:\n",
    "    test_speed_predictions = test_speed_predictions - np.min(test_speed_predictions) #if there is negative num in spd column\n",
    "    max_val = np.max(test_speed_predictions)      \n",
    "    normalized_arr_spd = test_speed_predictions / max_val\n",
    "    test_speed_predictions = np.where(normalized_arr_spd >= 0.5, 1, 0)\n",
    "else:\n",
    "    max_val = np.max(test_speed_predictions)      \n",
    "    normalized_arr_spd = test_speed_predictions / max_val\n",
    "    test_speed_predictions = np.where(normalized_arr_spd >= 0.5, 1, 0)\n",
    "submission_df = pd.DataFrame({\n",
    "    'image_id': test_ids.flatten(),\n",
    "    'angle': test_steering_predictions.flatten(),\n",
    "    'speed': test_speed_predictions.flatten()\n",
    "})\n",
    "submission_df.to_csv('aug_with_change_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9410b3-7866-4d7b-96fa-84567a7e2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate augmented images\n",
    "augmented_images = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "augmented_images = next(augmented_images)\n",
    "\n",
    "# plot the augmented images\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(12, 12))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(augmented_images[0][i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9fc9e8-04ce-4fd6-b78e-147cd616386d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Augmentation Technique                         Parameter Range\n",
      "0      Random Brightness                              [0.5, 1.5]\n",
      "1        Random Contrast                              [0.8, 1.2]\n",
      "2    Random Color Jitter                               -20 to 20\n",
      "3           Random Noise  Normal distribution with std dev of 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with the augmentation techniques\n",
    "data = {\n",
    "    'Augmentation Technique': ['Random Brightness', 'Random Contrast', 'Random Color Jitter', 'Random Noise'],\n",
    "    'Parameter Range': [\n",
    "        '[0.5, 1.5]',\n",
    "        '[0.8, 1.2]',\n",
    "        '-20 to 20',\n",
    "        'Normal distribution with std dev of 10'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bfbb65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
